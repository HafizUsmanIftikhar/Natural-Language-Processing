{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Muhammad Usman\n",
    "### P19-0096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Path to directory containing text files\n",
    "directory = \"/home/usman/Documents/Study/NLP/Assign-2\"\n",
    "\n",
    "# Generate a list of file paths for all the text files\n",
    "file_paths = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith(\".txt\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = {}\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, \"r\") as f:\n",
    "        text = f.read()\n",
    "        corpus[file_path] = text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the text data into a single string\n",
    "full_text = \" \".join(corpus.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ہاں وہ نہیں ہم کہ چلے جائیں\n",
      "کرتی ہے اثبات ‘ تراوش ‘ گویا\n",
      "میں زبان رکھتا ہوں کاش پوچھو کہ\n",
      "رخسارِ دوست   یہ مصرع\n",
      "\n",
      "بزمِ تماشا کہ برگ برگِ سمن ‘\n",
      "پر استوار ہوگا   کبھی آ\n",
      "دل ہوں جدا جدا   اقبال پرندے\n",
      "کہاں مے خانہ ہیں مدت سے خموش\n",
      "\n",
      "جامِ لب ریزِ سفالی ہے   کہ\n",
      "ہنوز ‘ جو چمن بے تابِ استقبال\n",
      "کام کیا طعنوں سے تو ؟ غالبؔ\n",
      "اکثر کئی منزل آئے   ان کو\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import random\n",
    "\n",
    "# Load the language model\n",
    "nlp = spacy.blank('ur')\n",
    "\n",
    "num_stanzas = 3\n",
    "num_verses = 4\n",
    "\n",
    "# Set the value of n for n-grams\n",
    "n = 2\n",
    "\n",
    "text=full_text\n",
    "# Preprocess the text\n",
    "text = text.lower()\n",
    "text = text.replace('\\n', ' ')\n",
    "\n",
    "# Tokenize the text\n",
    "doc = nlp(text)\n",
    "words = [token.text for token in doc]\n",
    "\n",
    "# Create n-grams\n",
    "ngrams = {}\n",
    "for i in range(len(words)-n):\n",
    "    gram = ' '.join(words[i:i+n])\n",
    "    if gram not in ngrams.keys():\n",
    "        ngrams[gram] = []\n",
    "    ngrams[gram].append(words[i+n])\n",
    "\n",
    "# Generate the poem\n",
    "poem = ''\n",
    "for i in range(num_stanzas):\n",
    "    for j in range(num_verses):\n",
    "        current_gram = random.choice(list(ngrams.keys()))\n",
    "        verse = current_gram.capitalize()\n",
    "        for k in range(7-n):\n",
    "            if current_gram not in ngrams.keys():\n",
    "                break\n",
    "            possible_words = ngrams[current_gram]\n",
    "            next_word = possible_words[random.randrange(len(possible_words))]\n",
    "            verse += ' ' + next_word\n",
    "            words = current_gram.split(' ')\n",
    "            words.append(next_word)\n",
    "            current_gram = ' '.join(words[1:])\n",
    "        poem += verse + '\\n'\n",
    "    poem += '\\n'\n",
    "\n",
    "print(poem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
